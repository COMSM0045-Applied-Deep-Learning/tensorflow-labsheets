{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Intro to BlueCrystal and Training Your First Fully Connected Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first lab session, you will learn the basics of implementing deep learning models using TensorFlow 1.2 and how to use BlueCrystal Phase 4 (BC4) for training them. The aim is to learn the principle of training a fully connected layer. \n",
    "\n",
    "### Objectives:\n",
    "\n",
    "1.- Build your first deep learning model using TensorFlow 1.2 for classifying Iris flowers using 3-dimensional data. \n",
    "\n",
    "2.- Train your model on BC4 and visualize the training process\n",
    "\n",
    "3.- Evaluate your model.\n",
    "\n",
    "\n",
    "## NOTICE:\n",
    "\n",
    "Please ensure you can successfully run the [GPU stress Test](../../BC4_Stress_Test/RunningTensorFlow.ipynb) before attempting Lab 1. This will ensure you have a working platform prior to proceeding with this lab sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. IRIS Flow Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 1936, British geneticist Ronald Fisher collected the IRIS Flow Dataset [Wiki](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "\n",
    "It contains 150 samples of three types of IRIS flowers. Each sample is described using four dimensions. Follow the wikipedia link above to look at the IRIS dataset file, and understand the various dimensions.\n",
    "\n",
    "The aim of this lab is to classify the IRIS flow dataset, using a fully connected `deep` network. We will actually build a shallow one of 3 layers only, but the principles extend to any depth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Running Your First BC4 Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Downloading Relevant Files\n",
    "\n",
    "* First, visit the [GitHub labsheet repository](https://github.com/COMSM0018-Applied-Deep-Learning/labsheets)\n",
    "* Clone the repository `git clone \"https://github.com/COMSM0018-Applied-Deep-Learning/labsheets.git\"`\n",
    "* Copy `Lab_1_DNNs` into a new folder which we will refer to as `/path_to_files/`\n",
    "* Using Jupyter notebook, open the file `Lab_1_DNNs/first_dnn.py`\n",
    "* Note that the file includes code to load the IRIS dataset - the same format as that on the Wiki page, and splits it into two: features and labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2   Copying files between your machine and BC4\n",
    "\n",
    "BlueCrystal Phase 4 (BC4) is the latest update on the University's High Performance Computing (HPC) machine. It includes 32 GPU-accelerated nodes, each of them with two NVIDIA Tesla P100 GPU accelerators and also a visualization node equipped with NVIDIA GRID GPUs; what matters to us are the Tesla P100 GPU accelerators that we will use for training your Deep Learing algorithms. \n",
    "\n",
    "Further information on BC4 and the support we have for it are available at: https://www.acrc.bris.ac.uk/acrc/phase4.htm\n",
    "\n",
    "There are two *modes* for using BC4: *Interactive* and *Batch*. We will use *Interactive* during lab sessions, since it allows the immediate excution of your program and you can see outputs directy on the terminal window (great for debugging); while the *Batch* method queues your job and generates files related with the excecution of your file. You will use *Batch* as part of the group project, so we will revisit that later.\n",
    "\n",
    "\n",
    "**NOW** copy the provided folder `Lab_1_DNNs` (which contains `first_dnn.py`, `tensorboard_params.sh`, `go_interactive.sh`) to your account in BC4. \n",
    "\n",
    "For copying individual files from your machine to your home directory on BC4 use the next example with `go_interactive.sh`:\n",
    "\n",
    "```$ scp  /path_to_files/Lab_1_DNNs/go_interactive.sh <your_UoB_ID>@bc4login.acrc.bris.ac.uk:```\n",
    "\n",
    "or all files at once by using: \n",
    "\n",
    "```$ scp -r /path_to_files/*  <your_UoB_ID>@bc4login.acrc.bris.ac.uk:```\n",
    "\n",
    "For copying back files from BC4 to your machine use the  command ```scp``` from a terminal on your machine, you can copy individual files, as well as directories:\n",
    "\n",
    "```$ scp  <your_UoB_ID>@bc4login.acrc.bris.ac.uk:/path_on_bc4/foo.foo   /path_in_your_machine/```\n",
    " \n",
    " Alternatively, you may wish to use SSHFS to mount a directory on BC4 to a directory using:\n",
    " \n",
    "```$ mkdir -p ~/bc4 && sshfs <your_UOB_ID>@bc4login.acrc.bris.ac.uk:/dir_on_bc4/ ~/bc4```\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.3 Logging in\n",
    "\n",
    "The connection to BC4 is done via SSH \n",
    "\n",
    "```$ ssh <your_UoB_ID>@bc4login.acrc.bris.ac.uk```\n",
    "\n",
    "You should see something like this in your home directory:\n",
    " \n",
    " ```\n",
    " Lab_1_DNNs\n",
    " |----------first_dnn.py \n",
    " |----------tensorboard_params.sh \n",
    " |----------go_interactive.sh```\n",
    " \n",
    "**NOTE: If you cannot see the file structure above, you have not copied the files correctly**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.4 Running Your Code\n",
    "\n",
    "Now run your current dnn code as follows: \n",
    "\n",
    "```$ ./go_interactive.sh ```\n",
    "\n",
    "Wait for a GPU to be allocated to you,\n",
    "\n",
    "\n",
    "```$ python first_dnn.py```\n",
    "\n",
    "Currently the code only loads your IRIS datafile. You can free the reserved GPU using\n",
    "\n",
    "```$ exit```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Let's code now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Prepare a Training/Testing split\n",
    "\n",
    "First, we need to separate the loaded file of samples **```data```** into training and testing - let's do a 2:1 split (100 samples for training and 50 samples for testing)\n",
    "\n",
    "\n",
    "**STOP**... before you proceed with this task, you first need to shuffle the file. **WHY?**\n",
    "\n",
    "**NOW**, generate a random seed from Numpy\n",
    "\n",
    "\n",
    "**NOW**, shuffle your data [hint: ```data = data.sample(frac=1).reset_index(drop=True)```]\n",
    "\n",
    "\n",
    "**NOW**, divide your data into ```train_x```, ```train_y```, ```test_x```, ```test_y```\n",
    "\n",
    "\n",
    "You can check you have correctly split the data by printing out the sizes of your variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Define a Perceptron!\n",
    "\n",
    "The first objective is to train a perceptron: $y=Wx-b$ given our training data ```train_x``` and ```train_y```\n",
    "\n",
    "Let's define first these variables for a **single** data point. Both ```x``` and ```y``` should be placeholders:\n",
    "\n",
    "\n",
    "```x = tf.placeholder(tf.float32, shape=[None, n_x])```\n",
    "\n",
    "**NOW**, go ahead and define $y$.\n",
    "\n",
    "\n",
    "**NOW**, define $W$ and $b$ as variables in Tensorflow (```tf.Variable```) with the right dimensions. Initialise to zero (we'll randomise this initialisation later)\n",
    "\n",
    "\n",
    "If defined correctly you can then define the predictions over y using the multiplication operator ([```tf.matmul```](https://www.tensorflow.org/api_docs/python/tf/matmul)) as well as the softmax operator [```tf.nn.softmax```](https://www.tensorflow.org/api_docs/python/tf/nn/softmax)\n",
    "\n",
    "**Note:** You have not trained anything yet, you are merely using random weights over placeholders for x and y\n",
    "\n",
    "**Debug:** Just debug to check you've done it correctly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Train a Perceptron!\n",
    "\n",
    "Now it is time to define the loss/cost function - that is the difference between the prediction, and the ground-truth\n",
    "\n",
    "There are a few ways to do this, let's try this one [we assume ```prediction``` is what you calculated in 3.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(prediction), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is only defining the cost function and not training for it. You will need an optimizer to do the job\n",
    "\n",
    "**NOW** Define a gradient descent ```optimiser```: [```tf.train.GradientDescentOptimizer```](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer) \n",
    "\n",
    "**HINT** You will need to call the ```minimize``` function of the optimiser with the right parameter (cost)\n",
    "\n",
    "**HINT** use a learning rate of 0.01 for now, we'll revisit this decision in later labs\n",
    "\n",
    "\n",
    "To get a random initialisation and optimise for a fixed number of iterations, try the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(10000):\n",
    "    sess.run([optimizer], feed_dict={x: train_x, y: train_y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Testing your trained perceptron\n",
    "\n",
    "You can now use the trained weights to test the prediction on, say, the first element in your test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(prediction, feed_dict={x: test_x[:1], y: test_y[:1]}).tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOW**, calculate the predictions of all your test set... This is the accuracy of your model\n",
    "\n",
    "You can also print out the model's accuracy during epochs (maybe print it out every 100 epochs?), to see how the model is being trained\n",
    "\n",
    "Debug and run, a sample of the **test** accuracy over time would be as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Accuracy of Perceptron at epoch 0 is 0.23999998\n",
    "Accuracy of Perceptron at epoch 10 is 0.97999996\n",
    "Accuracy of Perceptron at epoch 20 is 0.84000003\n",
    "Accuracy of Perceptron at epoch 30 is 0.97999996\n",
    "Accuracy of Perceptron at epoch 40 is 0.98000002\n",
    "Accuracy of Perceptron at epoch 50 is 0.98000002\n",
    "Accuracy of Perceptron at epoch 60 is 0.98000002\n",
    "Accuracy of Perceptron at epoch 70 is 0.98000002\n",
    "Accuracy of Perceptron at epoch 80 is 0.98000002\n",
    "Accuracy of Perceptron at epoch 90 is 0.98000002\n",
    "Accuracy of Perceptron at epoch 100 is 0.98000002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Define a *DEEP* fully connected network\n",
    "\n",
    "Now let's change our perceptron's definition to represent a fully connected network.\n",
    "\n",
    "We are aiming for a fully connected network that looks like this:\n",
    "\n",
    "```x(4 dimensions) - h1 (10 nodes) - h2 (20 nodes) - h3 (10 nodes) - y (3 classes)```\n",
    "\n",
    "Where h1 is the first layer of hidden nodes, and similarly for h2 and h3\n",
    "\n",
    "We will choose ReLU as our activation function\n",
    "\n",
    "We'll help you define the first layer (```h1```) using this code - **make sure you understand it!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = tf.Variable(tf.truncated_normal([n_x, h1], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1, shape=[h1]))\n",
    "h_fc1 = tf.nn.relu(tf.matmul(x, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOW** it's your turn to complete building the fully connected network.\n",
    "\n",
    "*Q: How many variables does your network contain??*\n",
    "\n",
    "Once done, you can define the loss function using softmax cross entropy as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_fcn = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=predictions_fcn, scope=\"Cost_Function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the Gradient descent optimiser, let's use the [Adagrad optimiser](https://www.tensorflow.org/api_docs/python/tf/train/AdagradOptimizer)\n",
    "\n",
    "**HINT** use a learning rate of 0.1 for this one\n",
    "\n",
    "**HINT** run your network for 3000 steps. *Q why do we need more iterations here?*\n",
    "\n",
    "**NOW**, optimise and calculate the accuracy for your test set as you did previously\n",
    "\n",
    "Print the accuracy every 100 epochs. Your output should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Accuracy of my first dnn at epoch 0 is 0.31999999\n",
    "Accuracy of my first dnn at epoch 100 is 0.31999999\n",
    "Accuracy of my first dnn at epoch 200 is 0.67999995\n",
    "Accuracy of my first dnn at epoch 300 is 0.67999995\n",
    "Accuracy of my first dnn at epoch 400 is 0.67999995\n",
    "Accuracy of my first dnn at epoch 500 is 0.67999995\n",
    "Accuracy of my first dnn at epoch 600 is 0.67999995\n",
    "Accuracy of my first dnn at epoch 700 is 0.74000001\n",
    "Accuracy of my first dnn at epoch 800 is 0.95999998\n",
    "Accuracy of my first dnn at epoch 900 is 0.95999998\n",
    "Accuracy of my first dnn at epoch 1000 is 0.95999998\n",
    "Accuracy of my first dnn at epoch 1100 is 0.95999998\n",
    "Accuracy of my first dnn at epoch 1200 is 0.95999998\n",
    "Accuracy of my first dnn at epoch 1300 is 0.95999998\n",
    "Accuracy of my first dnn at epoch 1400 is 0.95999998\n",
    "Accuracy of my first dnn at epoch 1500 is 0.97999996\n",
    "Accuracy of my first dnn at epoch 1600 is 0.97999996\n",
    "Accuracy of my first dnn at epoch 1700 is 0.97999996\n",
    "Accuracy of my first dnn at epoch 1800 is 0.97999996\n",
    "Accuracy of my first dnn at epoch 1900 is 0.97999996\n",
    "Accuracy of my first dnn at epoch 2000 is 0.97999996\n",
    "Accuracy of my first dnn at epoch 2100 is 0.97999996\n",
    "Accuracy of my first dnn at epoch 2200 is 0.97999996\n",
    "Accuracy of my first dnn at epoch 2300 is 0.97999996\n",
    "Accuracy of my first dnn at epoch 2400 is 0.97999996\n",
    "Accuracy of my first dnn at epoch 2500 is 0.97999996\n",
    "Accuracy of my first dnn at epoch 2600 is 0.97999996\n",
    "Accuracy of my first dnn at epoch 2700 is 0.97999996\n",
    "Accuracy of my first dnn at epoch 2800 is 0.97999996\n",
    "Accuracy of my first dnn at epoch 2900 is 0.97999996\n",
    "Accuracy of my first dnn at epoch 3000 is 0.97999996"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Summaries and Tensorboard\n",
    "Tensorboard allows for the visualisation of training and testing statistics. To do this we can run tensorboard on Blue Crystal and, via the use of port forwarding, view the results on your local machine. \n",
    "\n",
    "First, we need to indicate what we want to be saved in the summaries. For now we will save **some images** that are feed in to model, the **loss** and **accuracy** for every batch. \n",
    "\n",
    "First, you need to specify where the logs and summaries will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path = \"./logs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOW**, make sure you define all your DNN and all variables within a graph - we will revisit graphs in Lab2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.get_default_graph()\n",
    "with g.as_default():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each value you would like to log, define a name scope and use tf.summary.scalar to add the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    cost_fcn = tf.losses.softmax_cross_entropy(onehot_labels=y, predictions_fcn, scope=\"Cost_Function\")\n",
    "    tf.summary.scalar('loss', cost_fcn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To record all the summaries, you need to merge the summary (within ```g.as_default```). Then create two writers, one for the training data and the other for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(logs_path + '/train')\n",
    "test_writer = tf.summary.FileWriter(logs_path + '/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a summary per epoch, for both training and testing. You will need to output the summary from sess.run, then write it for both training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_writer.add_summary(summary_train, epoch)\n",
    "test_writer.add_summary(summary_test, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOW**, debug and run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Monitoring your training\n",
    "\n",
    "Follow the next steps for monitoring your training using Tensorboard:\n",
    "\n",
    "1. Using the blue crystal ssh login (2.2) change to the lab 1 directory:\n",
    "\n",
    "    ```$ cd Lab_1_DNNs/```\n",
    "    \n",
    "2. Switch to interactive mode, and note the change of the gpu login to a reserved gpu:\n",
    "\n",
    "    ```$ ./go_interactive.sh ```\n",
    "    \n",
    "3. Run the following script. It will pop up two values: `ipnport=XXXXX` and `ipnip=XX.XXX.X.X.`\n",
    "\n",
    "    ```$ chmod +x tensorboard_params.sh```\n",
    "\n",
    "    ```$ ./tensorboard_params.sh```\n",
    "    \n",
    "    **Write them down since we will use them for using TensorBoard.**\n",
    "\n",
    "4. Train the model using the command:\n",
    "    \n",
    "    ```$ python first_dnn.py & tensorboard --logdir=logs/ --port=<ipnport>```\n",
    "   \n",
    "   where `ipnport` comes from the previous step. It might take a minute or two before you start seeing the accuracy on the validation batch at every step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Visualising and Monitoring Your Training\n",
    "\n",
    "\n",
    "1. Open a **new Terminal window** on your machine and type: \n",
    "    \n",
    "    ``` ssh  <USER_NAME>@bc4login.acrc.bris.ac.uk -L 6006:<ipnip>:<ipnport>```</mark> \n",
    "    \n",
    "    where `ipnip` and `ipnport` comes from step 2 in **3.7**.\n",
    "\n",
    "2. Open your web browser (Use Chrome; Firefox currently has issues with tensorboard) and open the port 6006 (http://localhost:6006). This should open TensorBoard, and you can navigate through the summaries that we included.\n",
    "\n",
    "\n",
    "3. Click on **Accuracy** and **Loss**\n",
    "\n",
    "4. You should be able to see the train and test losses and accuracy like here,\n",
    "\n",
    "![](./loss_example_DNN.png)\n",
    "![](./accuracy_example_DNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Saving your trained model\n",
    "\n",
    "You should copy your log files back from BC4, and save them for your first lab portfolio\n",
    "\n",
    "```bash\n",
    "scp -r <your_UoB_ID>@bc4login.acrc.bris.ac.uk:/Lab_1_DNNs/logs   /path_in_your_machine/\n",
    "\n",
    "```\n",
    "\n",
    "Both your directory `logs/` and your `csv` file should be submitted as part of your Lab_1 portfolio (see [**section 6**](#6.-Preparing-Lab_1-Portfolio))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5. Closing all sessions\n",
    "\n",
    "Once the training has finished, **close all sessions** by typing `exit`. You need to do this twice for an **interactive session.** \n",
    "\n",
    "**Please make sure closing your session in order to release the gpu node.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Preparing Lab_1 Portfolio\n",
    "\n",
    "You should by now have the following files, which you can zip under the name `Lab_1_<username>.zip` \n",
    "\n",
    " ```\n",
    " Lab_1_<username>.zip\n",
    " |----------logs\\ \n",
    " |----------first_dnn.py\n",
    " ```\n",
    " \n",
    " Store this zip safely. You will be asked to upload all your labs' portfolio to ** SAFE at Week 10 ** - check SAFE for deadline details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ack: this lab is inspired by ideas from: [steadforce](https://steadforce.com/first-steps-tensorflow/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
